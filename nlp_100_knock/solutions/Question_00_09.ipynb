{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/i/Yuki/workspace/exercises/nlp_100_knock\n"
     ]
    }
   ],
   "source": [
    "%cd /mnt/i/Yuki/workspace/exercises/nlp_100_knock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlp100.github.io/ja/ch01.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00. 文字列の逆順"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = 'stressed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = 'パタトクカシーー'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パトカー'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str1 = 'パトカー'\n",
    "input_str2 = 'タクシー'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "print(''.join([v + w for v, w in zip(input_str1, input_str2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len([ch for ch in word if 'a' <= ch <= 'z' or 'A' <= ch <= 'Z']) for word in input_sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_sentence = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'H',\n",
       " 2: 'He',\n",
       " 3: 'Li',\n",
       " 4: 'Be',\n",
       " 5: 'B',\n",
       " 6: 'C',\n",
       " 7: 'N',\n",
       " 8: 'O',\n",
       " 9: 'F',\n",
       " 10: 'Ne',\n",
       " 11: 'Na',\n",
       " 12: 'Mi',\n",
       " 13: 'Al',\n",
       " 14: 'Si',\n",
       " 15: 'P',\n",
       " 16: 'S',\n",
       " 17: 'Cl',\n",
       " 18: 'Ar',\n",
       " 19: 'K',\n",
       " 20: 'Ca'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_dict = {}\n",
    "for i, word in enumerate(input_sentence.split(' ')):\n",
    "    if i + 1 in [1, 5, 6, 7, 8, 9, 15, 16, 19]:\n",
    "        word_dict[i + 1] = word[:1]\n",
    "    else:\n",
    "        word_dict[i + 1] = word[:2]\n",
    "\n",
    "word_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'I am an NLPer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(sentence, n=2, word_ngram=True):\n",
    "    if word_ngram:\n",
    "        lsts = sentence.split()\n",
    "    else:\n",
    "        lsts = sentence\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(lsts) - n + 1):\n",
    "        results.append(lsts[i:i + n])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n",
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "print(get_ngram(input_sentence, 2, False))\n",
    "print(get_ngram(input_sentence, 2, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_word1 = 'paraparaparadise'\n",
    "input_word2 = 'paragraph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = set(get_ngram(input_word1, word_ngram=False))\n",
    "Y = set(get_ngram(input_word2, word_ngram=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ag', 'is', 'ad', 'pa', 'ra', 'gr', 'ap', 'se', 'ph', 'ar', 'di'}\n",
      "{'ra', 'ap', 'ar', 'pa'}\n",
      "{'is', 'ad', 'di', 'se'}\n",
      "{'gr', 'ag', 'ph'}\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(X | Y)\n",
    "print(X & Y)\n",
    "print(X - Y)\n",
    "print(Y - X)\n",
    "print('se' in X)\n",
    "print('se' in Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_template(x, y, z):\n",
    "    return f'{x}時の{y}は{z}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12時の気温は22.4'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_template(x=12, y='気温', z=22.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cipher(chars):\n",
    "    return ''.join([chr(219 - ord(ch)) if 'a' <= ch <= 'z' else ch for ch in chars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I zn zm NLPvi'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cipher('I am an NLPer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typoglycemia(sentence):\n",
    "    def typoglycemia_word(word):\n",
    "        if len(word) <= 4:\n",
    "            return word\n",
    "        \n",
    "        return word[0] + ''.join(random.sample(word[1:-1], len(word[1:-1]))) + word[-1]\n",
    "\n",
    "    return [typoglycemia_word(word) for word in sentence.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I col’undt bieleve that I colud allautcy uenrantdsd what I was rnadieg : the penhnemoal pwoer of the haumn mind .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(typoglycemia(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "exercises"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
